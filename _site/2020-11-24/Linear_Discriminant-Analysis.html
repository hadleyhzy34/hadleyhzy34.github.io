<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Linear Discriminant Analysis | Ziyue(Hadley) Hou</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Linear Discriminant Analysis" />
<meta name="author" content="Ziyue Hou" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Linear Discriminant Analysis PCA vs LDA both for dimensionality reduction LDA is supervised, PCA is unsupervised LDA interested in the axes that maximize the seperation between multiple classes." />
<meta property="og:description" content="Linear Discriminant Analysis PCA vs LDA both for dimensionality reduction LDA is supervised, PCA is unsupervised LDA interested in the axes that maximize the seperation between multiple classes." />
<link rel="canonical" href="https://hadleyhzy34.github.io/home/2020-11-24/Linear_Discriminant-Analysis" />
<meta property="og:url" content="https://hadleyhzy34.github.io/home/2020-11-24/Linear_Discriminant-Analysis" />
<meta property="og:site_name" content="Ziyue(Hadley) Hou" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-24T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Linear Discriminant Analysis" />
<script type="application/ld+json">
{"headline":"Linear Discriminant Analysis","url":"https://hadleyhzy34.github.io/home/2020-11-24/Linear_Discriminant-Analysis","datePublished":"2020-11-24T00:00:00+08:00","dateModified":"2020-11-24T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://hadleyhzy34.github.io/home/2020-11-24/Linear_Discriminant-Analysis"},"author":{"@type":"Person","name":"Ziyue Hou"},"description":"Linear Discriminant Analysis PCA vs LDA both for dimensionality reduction LDA is supervised, PCA is unsupervised LDA interested in the axes that maximize the seperation between multiple classes.","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/home/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">


  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="180x180" href="/home/assets/icon-180x180.png">
<!--   <link rel="icon" type="image/png" sizes="180x180" href="/home/assets/icon-180x180.png">
  <link rel="icon" type="image/png" sizes="150x150" href="/home/assets/icon-150x150.png">
  <link rel="icon" type="image/png" sizes="128x128" href="/home/assets/icon-128x128.png"> -->
<!--   <link rel="icon" type="image/png" sizes="70x70" href="/home/assets/icon-70x70.png">
  <link rel="icon" type="image/png" sizes="48x48" href="/home/assets/icon-48x48.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/home/assets/icon-16x16.png"> -->
  <link rel="apple-touch-icon" type="image/png" sizes="180x180" href="/home/assets/icon-180x180.png">

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="https://hadleyhzy34.github.io/home/feed.xml" title="Ziyue(Hadley) Hou" />

  <!-- Google Analytics-->
  
</head>


  <body>

    <nav class="nav">
  <div class="nav-container">
    <a href="/home/">
      <img class="site-logo" src="/home/assets/icon.png">
      <h2 class="nav-title" >Ziyue(Hadley) Hou</h2>
    </a>
    <ul>
      <li><a href="/home/">Posts</a></li>
      <li><a href="/home/category">Category</a></li>
      <li><a href="/home/archive">Archive</a></li>
      <li><a href="/home/tags">Tags</a></li>
      <li><a href="/home/about">About</a></li>
    </ul>
  </div>
</nav>


    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Ziyue Hou
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2020-11-24 00:00:00 +0800">November 24, 2020</time>
    
  </div>

  <h1 class="post-title">Linear Discriminant Analysis</h1>
  <div class="post-line"></div>

  <h2 id="linear-discriminant-analysis">Linear Discriminant Analysis</h2>

<p>PCA vs LDA</p>
<ul>
  <li>both for dimensionality reduction</li>
  <li>LDA is supervised, PCA is unsupervised</li>
  <li>LDA interested in the axes that maximize the seperation between multiple classes.</li>
</ul>

<!--more-->

<h3 id="mathematical-analysis-and-proof">Mathematical Analysis and Proof</h3>

<ol>
  <li><a href="https://www.cnblogs.com/jerrylead/archive/2011/04/21/2024384.html">LDA by Jerry Lead</a></li>
</ol>

<h3 id="lda-with-real-examples">LDA with real examples:</h3>

<ol>
  <li>
    <p><a href="https://blog.csdn.net/weixin_45435206/article/details/103093920?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control">LDA summary and real example implementation</a></p>
  </li>
  <li>
    <p><a href="http://www.sci.utah.edu/~shireen/pdfs/tutorials/Elhabian_LDA09.pdf">A Tutorial on Data Reduction:LDA</a></p>
  </li>
</ol>

<h3 id="lda-implementation-using-python">LDA implementation using python:</h3>

<h2 id="source-data">Source data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">X_1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">]])</span>
<span class="n">X_2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">],[</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">],[</span><span class="mi">9</span><span class="p">,</span><span class="mi">5</span><span class="p">],[</span><span class="mi">8</span><span class="p">,</span><span class="mi">7</span><span class="p">],[</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">]])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">X_1</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">X_2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">marker</span><span class="o">=</span><span class="s">'s'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

</code></pre></div></div>

<p><img src="https://raw.githubusercontent.com/hadleyhzy34/machine_learning/master/lda/lda_scratch_files/lda_scratch_1_0.svg" alt="svg" /></p>

<h3 id="calculate-vector-mean">calculate vector mean</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_1_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_1_mean</span><span class="p">)</span>
<span class="n">X_2_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X_2</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_2_mean</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[3.  3.8]
[8.4 7.6]
</code></pre></div></div>

<h4 id="scatter-matrices-and-within-class-scatter-matrix-calculation">scatter matrices and within-class scatter matrix calculation</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#covariance matrix for each class
</span><span class="n">X_1_shift</span> <span class="o">=</span> <span class="n">X_1</span> <span class="o">-</span> <span class="n">X_1_mean</span>
<span class="n">X_1_cov</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X_1_shift</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_1_shift</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_1_cov</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[ 1.  -1.8]
 [-1.   0.2]
 [-1.  -0.8]
 [ 0.   2.2]
 [ 1.   0.2]]
[[ 1.   -0.25]
 [-0.25  2.2 ]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#covariance matrix for each class
</span><span class="n">X_2_shift</span> <span class="o">=</span> <span class="n">X_2</span> <span class="o">-</span> <span class="n">X_2_mean</span>
<span class="n">X_2_cov</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X_2_shift</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_2_shift</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_2_cov</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[ 0.6  2.4]
 [-2.4  0.4]
 [ 0.6 -2.6]
 [-0.4 -0.6]
 [ 1.6  0.4]]
[[ 2.3  -0.05]
 [-0.05  3.3 ]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># S_W = (5-1) * (X_1_cov + X_2_cov)
</span><span class="n">S_W</span> <span class="o">=</span> <span class="n">X_1_cov</span> <span class="o">+</span> <span class="n">X_2_cov</span>
<span class="k">print</span><span class="p">(</span><span class="n">S_W</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[ 3.3 -0.3]
 [-0.3  5.5]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#### Between-class scatter matrix calculation
</span><span class="n">X_mean</span> <span class="o">=</span> <span class="n">X_1_mean</span> <span class="o">-</span> <span class="n">X_2_mean</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_mean</span><span class="p">)</span>
<span class="n">X_T</span> <span class="o">=</span> <span class="n">X_mean</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_T</span><span class="p">)</span>
<span class="n">X_mean</span> <span class="o">=</span> <span class="n">X_mean</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_mean</span><span class="p">)</span>
<span class="n">S_B</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_T</span><span class="p">,</span><span class="n">X_mean</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">S_B</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[-5.4 -3.8]
[[-5.4]
 [-3.8]]
[[-5.4 -3.8]]
[[29.16 20.52]
 [20.52 14.44]]
</code></pre></div></div>

<h4 id="solve-generalized-eigenvalue-problem-for-the-matrix-to-obtain-the-linear-discriminants">Solve generalized eigenvalue problem for the matrix to obtain the linear discriminants</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">eig_vals</span><span class="p">,</span> <span class="n">eig_vecs_1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">eig</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">S_W</span><span class="p">).</span><span class="n">dot</span><span class="p">(</span><span class="n">S_B</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">eig_vecs_1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[12.20066445  0.        ]
[[ 0.90878558 -0.57549341]
 [ 0.41726342  0.81780642]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">S_W</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_T</span><span class="p">)</span>
<span class="n">S_inv</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">S_W</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">S_inv</span><span class="p">)</span>
<span class="n">eig_vecs_2</span> <span class="o">=</span> <span class="n">S_inv</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_T</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">eig_vecs_2</span><span class="p">)</span>
<span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">eig_vecs_2</span><span class="p">)</span>
<span class="n">eig_vec_2</span> <span class="o">=</span> <span class="n">eig_vecs_2</span><span class="o">/</span><span class="n">norm</span>
<span class="k">print</span><span class="p">(</span><span class="n">eig_vec_2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[ 3.3 -0.3]
 [-0.3  5.5]]
[[-5.4]
 [-3.8]]
[[0.30454042 0.0166113 ]
 [0.0166113  0.18272425]]
[[-1.7076412 ]
 [-0.78405316]]
[[-0.90878558]
 [-0.41726342]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">X_1</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">X_2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">marker</span><span class="o">=</span><span class="s">'s'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">eig_vecs_1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">eig_vecs_1</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span><span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axline</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="n">eig_vecs_1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">eig_vecs_1</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.9087855843337986 0.41726342004431227
</code></pre></div></div>

<p><img src="https://raw.githubusercontent.com/hadleyhzy34/machine_learning/master/lda/lda_scratch_files/lda_scratch_12_1.svg" alt="svg" /></p>

<h4 id="check-result-of-pca">check result of PCA</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">datasets</span> <span class="o">=</span> <span class="n">X_1</span> <span class="o">+</span> <span class="n">X_2</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1">#chosen number of dimensions
</span><span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">datasets</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>   
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[-0.98195639 -0.18910752]
 [ 0.18910752 -0.98195639]]
[5.35777472 3.74222528]
[[-1.68459473 -0.2866018 ]
 [ 3.2251872  -1.2321394 ]
 [ 1.03574813  3.26300871]
 [ 0.09021052 -1.64677323]
 [-2.66655112 -0.09749428]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">X_1</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_2</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">X_2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">marker</span><span class="o">=</span><span class="s">'s'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span><span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axline</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span><span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axline</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span><span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-0.9819563867314219 0.18910752115495139
</code></pre></div></div>

<p><img src="https://raw.githubusercontent.com/hadleyhzy34/machine_learning/master/lda/lda_scratch_files/lda_scratch_15_1.svg" alt="svg" /></p>

<p>Reference:</p>
<ul>
  <li>
    <p><a href="https://sebastianraschka.com/Articles/2014_python_lda.html">Linear Discriminant Analysis-Bit by Bit</a></p>
  </li>
  <li>
    <p><a href="https://blog.csdn.net/brucewong0516/article/details/78684005?utm_source=blogxgwz7">Linear Disciminant Analysis using sklearn</a></p>
  </li>
  <li>
    <p><a href="https://www.python-course.eu/linear_discriminant_analysis.php">Supervised Learning Dimensionality reduction:LDA</a></p>
  </li>
  <li>
    <p><a href="https://blog.csdn.net/qq_44766883/article/details/109893062">LDA theory explanation</a></p>
  </li>
</ul>

</div>



<div class="pagination">
  
    <a href="/home/2020-11-24/Matplotlib-cheat-sheet" class="left arrow">&#8592;</a>
  
  
    <a href="/home/2020-11-23/Principal-Component-Analysis" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>
    </main>

    <footer class= "blog-footer">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
          <p>
            <a href="#" class="fa fa-facebook"></a>
            <a href="#" class="fa fa-twitter"></a>
            <a href="#" class="fa fa-github"></a>
            <a href="#" class="fa fa-linkedin"></a>
            <a href="#" class="fa fa-wechat"></a>
            <a href="#" class="fa fa-weibo"></a>
            <a href="#" class="fa fa-google"></a>
            <a href="#" class="fa fa-skype"></a>
          </p>
        
<!--     <p>Hadley_hzy@hotmail.com</p> -->

    <p>Â© Ziyue(Hadley) Hou 2021<!--  --></p>

  </footer>

  </body>
</html>
